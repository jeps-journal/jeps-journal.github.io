---
layout: post
title: ! 'Structural Equation Modeling: What is it, what does it have in common with
  hippie music, and why does it eat cake to get rid of measurement error?'
date: 
type: post
published: false
status: draft
categories:
- Research Methodology
tags:
- covariance matrix
- latent variable modeling
- psychedelic rock
- statistics
- structural equation modeling
meta:
  _edit_last: '24'
  _syntaxhighlighter_encoded: '1'
  editInHTML: 'off'
  _thumbnail_id: '4080'
author:
  login: Peter Edelsbrunner
  email: peter.edelsbrunner@ifv.gess.ethz.ch
  display_name: Peter Edelsbrunner
  first_name: Peter
  last_name: Edelsbrunner
---
<p>Statistics courses in Psychology nowadays frequently encompass a powerful statistical tool named <em>Structural Equation Modeling</em> (SEM). For those of you who did not learn about SEM or who do not remember much, this article might be super helpful! We aim at providing enriching perspectives on the not so trivial question <em>What is SEM?</em>. To tackle this question, we explore major developments in the world of music and statistics in the late 1960s. We touch the concept of <em>la</em><em>tent variables</em> and the connected topic of what it actually means to <em>get rid of measurement error</em>, something often pointed out as one of the main strengths of SEM. Finally, we will point out conceptual issues of models including latent variables, and we will touch <em>how to do it Bayesian?</em>. We aim at providing an understanding of the capabilities of SEM, its relation to more classical statistical techniques, of some crucial theoretical and statistical assumptions underlying latent variables, and related issues and criticism. The following is our view on some developments in music and statistics; we invite you to leave comments to discuss and add your own enriching views!</p>
<p><a href="http://blog.efpsa.org/wp-content/uploads/2015/11/tf1hc.jpg"><img class=" wp-image-4062 aligncenter" src="{{ site.baseurl }}/assets/tf1hc.jpg" alt="tf1hc" width="238" height="238" /></a></p>
<h2><strong>History: The Roots of Structural Equation Modeling</strong></h2>
<p>Let us start with music. Well before our world reached the stage of rock legends <a href="http://ytcropper.com/cropped/dw563a1fc4c1efb">crushing scenes in school uniforms</a> and children’s toys perverted into <a href="http://ytcropper.com/cropped/gf563a201d349d3">horryfying metal clowns</a>, in the mid 60s benign miksop duos were considered evilish rock music and some <a href="http://ytcropper.com/cropped/UJ563a21792fd5b">slanting voice</a> was sufficient to make a wild punk song. Hard rock became hip, combining the power of the electric guitar with bluesy elements, however still limited to rather <a href="https://youtu.be/zt51rITH3EA?t=19">traditional pop music structures</a>.</p>
<p>Similarly, in statistics, researchers in the mid 60s could choose from a limited number of major techniques that were useful but quite specific and limited in their scope. First, in the beginnings of the 20th century, Spearman (1904, 1907) had developed <a href="https://en.wikipedia.org/wiki/Factor_analysis"><em>factor analysis</em></a> related techniques that he initially used to examine his assumption of a general factor of intelligence. This technique allowed reducing a large number of variables to a smaller number of underlying constructs that are represented by non-observed or <a href="https://en.wikipedia.org/wiki/Latent_variable"><em>latent variables</em></a><em>, </em>which we will discuss later. Second, Pearson (1908) and Fisher (1922, 1925) had developed <em><a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_regression">multiple regression</a></em> and related techniques that allowed estimating the relation between two constructs while controlling for the otherwise biasing effects of confounding variables. Third, Wright (1918, 1921, 1934) had developed <em><a href="https://en.wikipedia.org/wiki/Path_analysis_(statistics)">path analysis</a></em> related techniques in which causal relations between various variables can be estimated at the same time. In <strong>Figure 1</strong>, an overview of this status quo in the 1960s is depicted, using simplified <em>path diagram</em> visualizations that are often used to depict SEMs.</p>
<p><a href="http://blog.efpsa.org/wp-content/uploads/2015/11/SEM_Figure1.png"><img class="wp-image-4066 aligncenter" src="{{ site.baseurl }}/assets/SEM_Figure1.png" alt="SEM_Figure1" width="789" height="247" /></a></p>
<p style="text-align: center"><strong>Figure 1.</strong> A graphical depiction of three major statistical techniques available in the 1960s.</p>
<p>Based on this status quo, thrilling developments were to follow, both in music and in statistics. In the mid- to late sixties, the hippies finally broke out of traditional pop music structures, and some of the first SEM related techniques were introduced, which would allow researchers to break out of the boundaries of traditional statistical methods.</p>
<p>In music, the hippies took the logical next step and merged blues and rock music with progressive, sometimes substance induced thinking. This yielded a unifying, more general and thus freeing framework that is known as <a href="https://en.wikipedia.org/wiki/Psychedelic_rock"><em>psychedelic rock</em></a>. In statistics, similarly but perhaps less substance induced, some genius researchers took the logical next step and merged the logics of factor analysis, of multiple regression, and path analysis with progressive thinking. This yielded the unifying, more general framework of <em>covariance structure modeling</em> (Jöreskog, 1969, 1970), which is the core framework underlying SEM.</p>
<p>To visualize this technique, a “full” structural equation model is depicted in <strong>Figure 2</strong>. <em>Full</em> means that the model has measurement parts and a structural part. The model combines aspects of all three mentioned classical statistical approaches. In the <em>measurement</em> parts of the model, which translate collected data into psychological constructs represented as <a href="https://en.wikipedia.org/wiki/Latent_variable"><em>latent variables</em></a>, structures similar to factor analysis are modeled. In the <em>structural</em> part of the model, which depicts how the psychological constructs relate to each other, aspects similar to multiple regression and path analysis are modeled.</p>
<p><a href="http://blog.efpsa.org/wp-content/uploads/2015/11/SEM_Figure2.png"><img class="wp-image-4067 aligncenter" src="{{ site.baseurl }}/assets/SEM_Figure2.png" alt="SEM_Figure2" width="730" height="465" /></a></p>
<p style="text-align: center"><strong>Figure 2.</strong> A depiction of a “full” structural equation model, including three <em>measurement</em> parts (one entangled in red) and a <em>structural </em>part (entangled in green). The latent variables η1 – η3 represent theoretical constructs that are estimated from the covariance matrix of a dataset that consists of y and z variables. Dashed arrows indicate in which parts of the model the three formerly discussed, traditional techniques (factor analysis, multiple regression, path models) are merged and represented.</p>
<p>Boom! It is the end of the rocking 60s, a technique called <em>covariance structure modeling</em> enters the field and turns out to be a blast, apparently capable of integrating various major approaches!</p>
<p><strong><img class="wp-image-4064 aligncenter" src="{{ site.baseurl }}/assets/th99c.jpg" alt="th99c" width="252" height="252" /></strong></p>
<h2 style="text-align: left"><strong>Intermediate Result: What is SEM?</strong></h2>
<p>So far, we have described that SEM is based on <em>covariance structure modeling</em>, which is able to combine the capabilities of various prior techniques. In addition, this is not yet it; apart from these classical techniques, SEM can accommodate a baffling myriad of further traditional and modern types of statistical models. For example, SEM can be used to model variances, means, t-tests, and ANOVA models (Green &amp; Thompson, 2012), group comparisons (van de Schoot et al., 2012), categorical variables, latent class models (Edelsbrunner et al., 2015), multilevel models (Televantou et al., 2015), item response theory models (Glockner-Rist &amp; Hoijtink, 2003), and there are various SEM techniques for longitudinal data resembling repeated measures t-tests (Coman et al., 2013) and repeated measures ANOVA (Barker, Rancourt, &amp; Velalian, 2014), cross-lagged models (Little, 2011), change score models (McArdle &amp; Nesselroade, 2014), and growth curve models (Little, 2011). Besides these modeling capabilities, it is often pointed out that SEM offers model fit indices that can help detect statistical misspecifications and theoretical misassumptions (see e.g., Geiser, 2012; Little, 2013). Also, SEM allows relaxing various strong statistical assumptions of more traditional models that often do not hold, for example by modeling varying variances between groups, correcting standard errors and model fit values for non-normality in the data, including cases with missing data in the analysis, and modeling parameter heterogeneity and multimodality by using multiple group and mixture models (Agan et al., 2015; Hoyle, 2012; Little, 2013).</p>
<p>Many textbooks similarly recite SEM’s strengths and modeling capabilities for defining it. However, is this sufficient to answer the question what SEM is? We don’t think so. As we have already mentioned, SEM is usually based on <em>covariance structure modeling</em>, which offers a convenient framework for modeling <a href="https://en.wikipedia.org/wiki/Latent_variable"><em>latent variables</em></a>. For arriving at a proper definition, we dig into this main characteristic of SEM. Let’s see what it does!</p>
<h2 style="text-align: left"><strong>Latent Variables: Chanting away measurement error</strong></h2>
<p>Psychological characteristics are not directly measurable. We can ask people questions, we can measure their heart rate or brain activity, we can observe them in social interactions, but the data that we get out of these endeavors do not directly tell us about people’s psychological characteristics. Rather, we assume that our data relate to people’s psychological characteristics in ways that we try to model. In SEM, we often do this by assuming that various variables correlate because they all indicate the level of the same psychological construct.</p>
<p>For example, in the assessment of creativity, people are often asked to bring up many novel and useful ideas about what to do with everyday objects such as a can, a car tire, or a brick (e.g. Benedek et al., 2014). We can count how many ideas people come up with for each of these items. How should we use the resulting numbers to determine how creative people are? The statistician’s answer to this question is the <a href="https://en.wikipedia.org/wiki/Latent_variable"><em>latent variable</em></a>, the idea of which is depicted in Figure 3.</p>
<p><a href="http://blog.efpsa.org/wp-content/uploads/2015/11/SEM_Figure-3.png"><img class="wp-image-4068 aligncenter" src="{{ site.baseurl }}/assets/SEM_Figure-3.png" alt="SEM_Figure 3" width="509" height="429" /></a></p>
<p style="text-align: center"><strong>Figure 3.</strong> Depiction of a <a href="https://en.wikipedia.org/wiki/Latent_variable"><em>latent variable</em></a> (η1) in SEM and how it represents correlations between indicators (y1-y3) and their relations with other variables (z1). Following the paths depicted in grey, it is apparent that the .3-relations (in green) of the y variables with the z variable are explained and summarized by the construct’s correlation with the z1 variable (.42) multiplied with the indicator variables’ loading (.71). The indicator variables’ intercorrelations (.5) are explained through multiplying their factor loadings (.71*.71 = .5).</p>
<p>In <strong>Figure 3</strong>, a <em><a href="https://en.wikipedia.org/wiki/Covariance_matrix">covariance matrix</a></em> is depicted, showing that people’s number of novel ideas is positively correlated across the three items (variables y1-y3): The more ideas that have people for the can, the more ideas they tend to have as well for what to do with the car tire and the brick. Why is this so? The creativity researcher’s assumption is<em>, surprise surprise</em>, because some people are more creative than others! From a psychological view, this assumption entails that people’s creativity is the psychological construct underlying their ideas on all three items. Translating this into statistics, creativity is a <em><a href="https://en.wikipedia.org/wiki/Latent_variable">latent variable</a></em> that explains the correlations between the three items because it <em>caused</em> the variation underlying them. In the figure, this is indicated by arrows pointing from the latent variable representing creativity towards the variables representing people’s number of ideas on the three items.</p>
<p>Now, let’s see what it means to <em>get rid of measurement error</em>. In the correlation matrix in Figure 3 there is also the variable z1 which represents people’s score on a questionnaire assessing their <em>openness</em>. People’s openness for new experiences is positively correlated with their creativity: Being open might free people’s minds, and free minds might be open! In the correlation matrix, we see that the three creativity-items show correlations of .3, with z1, the openness scores. In SEM, instead of modeling all of these three correlations, we sum up the items’ variance that represents creativity into a<em> latent variable, η1</em>. In this latent variable, all the variance that the three items share is summed up. All the variance that the items do not share is assumed to be measurement error, which does not represent people’s creativity but rather assessment artifacts and randomness, and is thus left out of the latent variable. This can be seen in the three paths from the η1 variable to the y variables. These paths are factor loadings that show how strongly each item represents the construct that it is supposed to measure, in our case creativity. The <em>factor loadings</em> are all .71, which is lower than 1, indicating that only parts of the y variables’ variances go into the latent variable.</p>
<p>In <strong>Figure 4</strong>, it is depicted how the measurement error variance is cut out of the indicator variables and only the share of variance which supposedly really represents creativity goes into the latent variable. The initial correlation between any of the y variables and z is .30. This is represented as an overlap in the variables’ variances in the upper part of Figure 4. In the latent variable, only a part of any of the y variables’ variances is represented. However, the overlap in variance with the z variable is still the same. Thus, the proportion of the variables’ overlapping variance is now larger. As a result, the correlation that the latent variable has with z1 is estimated to be .42, which is higher than the three y-variables’ individual correlation estimates with the z1 variable, because it is corrected for measurement error, by just cutting it out of the variance cake! This is the reason why you can get rid of measurement error by using SEM. This might look like magic, but it is not; it is strong theory about a measured construct, translated into an SEM!<img class="wp-image-4069 aligncenter" src="{{ site.baseurl }}/assets/SEM_Figure-4.png" alt="SEM_Figure 4" width="455" height="478" /></p>
<p style="text-align: center"><strong>Figure 4</strong>. A variance cake illustration of the process of creating a latent variable.</p>
<p>If you would like to reproduce the model and results from this example, run the following code in the free <em>R</em> software that you can easily download and install from <u><a href="https://www.r-project.org/">here</a></u>:</p>
<p>[sourcecode language="R"]</p>
<p>install.packages(&quot;lavaan&quot;) # Install lavaan package; only necessary once<br />
install.packages(&quot;semPlot&quot;) # Install semPlot package; only necessary once<br />
library(lavaan) # Package for SEM<br />
library(semPlot) # Package to draw SEMs&lt;/pre&gt;</p>
<p># Define correlation matrix<br />
lower &lt;- '<br />
1<br />
.5 1<br />
.5 .5 1<br />
.3 .3 .3 1 '</p>
<p>crea.cov &lt;- getCov(lower, names = c(&quot;y1&quot;, &quot;y2&quot;, &quot;y3&quot;, &quot;z&quot;)) # Assign variable names</p>
<p># Define model<br />
crea.model &lt;- '<br />
# latent variable<br />
eta     =~ y1 + y2 + y3<br />
# regression/correlation<br />
z ~ eta<br />
'</p>
<p># Fit model<br />
fit &lt;- sem(crea.model,<br />
sample.cov = crea.cov,<br />
sample.nobs = 100)</p>
<p># Investigate model output<br />
summary(fit, standardized = TRUE)</p>
<p># Visualize model<br />
semPaths(fit,<br />
style = &quot;lisrel&quot;,<br />
&quot;std&quot;,<br />
rotation = 3,<br />
)</p>
<p>[/sourcecode]</p>
<p>To yield parameter estimates in complex SEMs, iterative algorithms have to be used, for example a <u><a href="https://en.wikipedia.org/wiki/Maximum_likelihood">maximum likelihood</a></u> estimator. The relations of the estimates to the covariance matrix are explained in <strong>Figure 3:</strong> The factor loadings are estimated in a way that they represent the intercorrelations of the items; the correlation of the latent variable with the z variable is estimated so that it represents the correlations of the items with the z variable, when corrected for their factor loading. The estimation of SEMs can be well understood by applying Wright’s path tracing rules (Wright, 1934). Developing a generic understanding of latent variables and their estimation can take years, but eventually for SEM users it will be worth the time. The application and interpretation of latent variables is attached to various statistical and philosophical topics that have been heavily debated for decades. Let us sum up what we discussed so far and shortly get into some of these issues.</p>
<h2><strong>Unification increasing Freedom: Theoretical Concerns and Bayesian Implementation</strong></h2>
<p>Our discussion and example showed that based on the principle of covariance structure modeling, basically any assumptions can be modeled that are related to correlations between variables. This approach can be extended to include variables’ variances and means, to enable the full repertoire of models that SEM can cover. Then, SEM enables psychology students to go beyond the traditional statistical techniques that they usually learn in basic statistics courses: In covariance structure based modeling, they can implement complex theoretical assumptions without necessarily considering whether their models represent t-tests, ANOVAs, or other traditional models that they have learned about. Try SEM and enjoy the increased level of freedom!</p>
<p>Are there any concerns? Indeed, in various Psychology related fields SEM has superseded more classical regression-related techniques that cannot include the explicit modeling of latent variables. Unfortunately, the great flexibility of SEM and power of latent variables have led to mindless and reductionist modeling habits in many fields. Large numbers of measured variables are often modeled in sparse latent variable models, supposedly getting rid of measurement error and redundant information, despite concerns that statistical or theoretical assumptions might not be adequately met (Goldstein, 1979; Heene, Bollmann, &amp; Bühner, 2014). While we acknowledge that parsimony is a guiding principle that is often useful in science, we share concerns with researchers pointing out the very strong theoretical and statistical assumptions underlying latent variables. For example, when one models creativity as a latent variable, arguably they assume that this psychological characteristic really exists in people’s minds, which however is an assumption that is difficult to test directly (Borsboom, Mellenberg, &amp; van Heerden, 2003). Also, one should be aware that summarizing information from many indicator variables in one single latent variable necessarily results in loss of the indicator variables’ differential information. Statistically, one usually assumes normal distributions for all observed and latent variables and linear relations between the latent and observed variables, assumptions which are seldom met and arguably quite arbitrary.</p>
<p>Finally, it is an erroneous habit to read out unfounded theoretical conclusions from the mere fitting of SEMs. In general, SEMs do not have the power to reveal great theory. In case one does not have strong theory that supports the application of such high level latent variable models, some alternative methods to the predominant habit of using SEM have been proposed that might be more supportive for well-founded theory development (Cramer, Waldorp, van der Maas, &amp; Borsboom, 2010; van der Maas et al., 2006). However, this does not imply that SEM is useless; one should just be informed about its strong theoretical prerequisites before engaging in uninformed practices. Strong models demand strong theoretical assumptions!</p>
<p>The statistics hipsters among you might come up with the question <em>Is there a way to do it Bayesian?.</em> Bayesian statistics is a way of estimating parameters and testing hypotheses that overcomes many conceptual problems related to the use of p-value hypothesis testing and <a href="https://en.wikipedia.org/wiki/Frequentist_inference"><em>frequentist</em></a> statistics that Psychology students usually learn. It is on the advance to become the number one statistics framework of many researchers, intruding even  hippie music at conferences, and  you can read about it in the JEPS Bulletin <a href="http://blog.efpsa.org/2014/11/17/bayesian-statistics-what-is-it-and-why-do-we-need-it-2/">here</a> and <a href="http://blog.efpsa.org/2015/08/03/bayesian-statistics-why-and-how/">here</a>. Luckily, SEM is not a family of statistical models connected to either frequentist or Bayesian statistics. You can estimate SEMs in any way you want, and if you want to do it Bayesian, the free and convenient <a href="https://jasp-stats.org/">JASP</a> software is blasting off an SEM module, the <a href="http://www.statmodel.com">Mplus</a> software is slightly more complex but also more powerful, and for even more modeling opportunities you can write your own models for the <a href="http://mcmc-jags.sourceforge.net">JAGS</a> package in the free <a href="http://www.r-project.org">R</a> software, or in <a href="http://www.mc-stan.org">Stan</a>. Bayesian SEM has been recommended for its high flexibility towards complex data situations (Edelsbrunner &amp; Schneider, 2013; Song &amp; Lee, 2012). Recently, there has been some user friendly literature on Bayesian SEM (Kaplan &amp; Depaoli, 2012; van de Schoot et al., 2014).</p>
<h2><strong>Conclusion: What is SEM?</strong></h2>
<p>A little journey through the world of music and statistics in the 60s and beyond brought us some interesting insights. We learned about expressing musical freedom, about modeling complex theories based purely on correlations between variables, about modeling something which we don’t directly measure, about eliminating measurement error from the estimation of interesting parameters, and about the issues emerging from mindless applications of these procedures. We have seen a large number of models that can be accommodated within the framework of SEM.</p>
<p>In music, merging blues and rock with creativity enhanced peoples’ possibilities: Breaking out of musical borders, any ideas that had to do with rock music instruments could be expressed in psychedelic rock. The similarity to SEM is astonishing: Breaking out of specific models and measurement error, any ideas that have to do with covariances, variances, means, and latent variables can be expressed as structural equation models. Cheers to musical and statistical <a href="http://ytcropper.com/cropped/Qx563a2dee6ce88">freedom</a>!</p>
<p>Many definitions of SEM just mention some of the models and possibilities that SEM offers. For the conclusion of this article, we acknowledge the dazzling multitude of SEM related models and opportunities to arrive at a quite general definition that we find appealing: “Structural Equation Modeling (SEM) is a comprehensive statistical approach to testing hypothesis about relations among observed and latent variables” (Hoyle, 2012). For this means, we believe it a framework that will stick around and enrich our research lives for many years to come.</p>
<p>&nbsp;</p>
<h2><strong>Suggested Readings</strong></h2>
<p><em>Software based introductions to SEM:</em></p>
<p>Geiser, C. (2012). <em>Data analysis with Mplus</em>. Guilford Press.</p>
<p>Beaujean, A. A. (2014). <em>Latent variable modeling using R: A step-by-step guide</em>. Routledge.</p>
<p><em>Advanced and longitudinal SEM:</em></p>
<p>Little, P. T. D. (2013). <em>Longitudinal structural equation modeling</em>. Guilford Press.</p>
<p>McArdle, J. J., &amp; Nesselroade, J. R. (2014). <em>Longitudinal data analysis using structural equation models</em>. American Psychological Association.</p>
<p><em>Theoretical background of latent variables:</em></p>
<p>Borsboom, D. (2008). Latent variable theory. <em>Measurement: Interdisciplinary Research &amp; Perspective, 6</em>, 25–53. http://doi.org/10.1080/15366360802035497</p>
<p>Borsboom, D., Mellenbergh, G. J., &amp; van Heerden, J. (2003). The theoretical status of latent variables. <em>Psychological Review, 110</em>, 203–219. http://doi.org/10.1037/0033-295X.110.2.203</p>
<p><em>More history and background of SEM?</em></p>
<p>Skrondal, A., &amp; Rabe-Hesketh, S. (2007). Latent variable modelling: A survey. <em>Scandinavian Journal of Statistics, 34</em>, 712-745.</p>
<p>Matsueda, R. L., &amp; Press, G. (2012). Key advances in the history of structural equation modeling. In: Hoyle, R. (Ed.) <em>Handbook of structural equation modeling</em> (pp. 17-42). Guilford New York, NY.</p>
<h2 style="text-align: center">References</h2>
<p>Agan, M. L., Costin, A. S., Deutz, M. H., Edelsbrunner, P. A., Záliš, L., &amp; Franken, A. (2015). Associations between risk behaviour and social status in European adolescents. <em>European Journal of Developmental Psychology, 12</em>, 189-203.</p>
<p>Barker, D. H., Rancourt, D., &amp; Jelalian, E. (2014). Flexible models of change: Using structural equations to match statistical and theoretical models of multiple change processes. <em>Journal of Pediatric Psychology, 39</em>, 233–245.</p>
<p>Beaujean, A. A. (2014). <em>Latent variable modeling using R: A step-by-step guide</em>. Routledge.</p>
<p>Benedek, M., Jauk, E., Sommer, M., Arendasy, M., &amp; Neubauer, A. C. (2014). Intelligence, creativity, and cognitive control: the common and differential involvement of executive functions in intelligence and creativity. <em>Intelligence, 46, </em>73-83.</p>
<p>Borsboom, D. (2008). Latent variable theory. <em>Measurement: Interdisciplinary Research &amp; Perspective, 6</em>, 25–53.</p>
<p>Borsboom, D., Mellenbergh, G. J., &amp; van Heerden, J. (2003). The theoretical status of latent variables. <em>Psychological Review, 110</em>, 203–219.</p>
<p>Coman, E. N., Picho, K., McArdle, J. J., Villagra, V., Dierker, L., &amp; Iordache, E. (2013). The paired t-test as a simple latent change score model. <em>Frontiers in Psychology, 4</em>, 738.</p>
<p>Cramer, A. O. J., Waldorp, L. J., van der Maas, H. L. J., &amp; Borsboom, D. (2010). Comorbidity: A network perspective. Behavioral and Brain Sciences, 33(2-3), 137–150.</p>
<p>Edelsbrunner, P. A., Schalk, L., Schumacher, R., &amp; Stern, E. (2015). Pathways of conceptual change: Investigating the influence of experimentation skills on conceptual knowledge development in early science education. <em>Proceedings of the 37th Annual Conference of the Cognitive Science Society, 620-625</em>. Austin, Texas: Cognitive Science Society.</p>
<p>Edelsbrunner, P. A., &amp; Schneider, M. (2013). Modelling for Prediction vs. Modelling for Understanding: Commentary on Musso et al.(2013). <em>Frontline Learning Research, 2</em>, 99-101.</p>
<p>Fisher, R. A. (1922). The goodness of fit of regression formulae, and the distribution of regression coefficients. <em>Journal of the Royal Statistical Society, 85</em>, 597–612.</p>
<p>Fisher, R. A. (1925). <em>Statistical Methods for Research Workers</em>. Oliver and Boyd, Edinburgh.</p>
<p>Geiser, C. (2012). <em>Data analysis with Mplus</em>. Guilford Press.</p>
<p>Glockner-Rist, A., &amp; Hoijtink, H. (2003). The best of both worlds: Factor analysis of dichotomous data using item response theory and structural equation modeling. <em>Structural Equation Modeling, 10</em>, 544-565.</p>
<p>Goldstein, H. (1979). Consequences of Using the Rasch Model for Educational Assessment. <em>British Educational Research Journal, 5</em>, 211-220.</p>
<p>Green, S. B., &amp; Thompson, M. S. (2012). A flexible structural equation modeling approach for analyzing means. In Hoyle, R. H. (Ed.) <em>Handbook of structural equation modeling</em> (pp. 393 – 416). Guilford Press.</p>
<p>Heene, M., Bollmann, S., &amp; Bühner, M. (2014). Much ado About Nothing, or Much to do About Something?: Effects of Scale Shortening on Criterion Validity and Mean Differences. <em>Journal of Individual Differences, 35</em>, 245–249.</p>
<p>Hoyle, R. H. (Ed.). (2012). <em>Handbook of structural equation modeling</em>. Guilford Press.</p>
<p>Jöreskog, K. G. (1969). A general approach to confirmatory maximum likelihood factor analysis. <em>Psychometrika, 34</em>, 183–202.</p>
<p>Jöreskog, K. G. (1970). A general method for analysis of covariance structures. <em>Biometrika, 57</em>, 239–251.</p>
<p>Kaplan, D., &amp; Depaoli, S. (2012). Bayesian structural equation modeling. In R. Hoyle (Ed.), <em>Handbook of structural equation modeling</em> (pp. 650–673). Guilford New York, NY.</p>
<p>Kline, R. B. (2011). <em>Principles and practice of structural equation modeling. </em>New York: Guilford Press.</p>
<p>Little, P. T. D. (2013). <em>Longitudinal structural equation modeling</em>. Guilford Press.</p>
<p>McArdle, J. J., &amp; Nesselroade, J. R. (2014). <em>Longitudinal data analysis using structural equation models</em>. American Psychological Association.</p>
<p>Pearson, K. (1908). On the generalized probable error in multiple normal correlation. <em>Biometrika, 6</em>, 59-68.</p>
<p>Song, X.-Y., &amp; Lee, S.-Y. (2012). <em>Basic and Advanced Bayesian Structural Equation Modeling</em>. John Wiley &amp; Sons.</p>
<p>Spearman, C. (1904). The proof and measurement of association between two things. <em>The American journal of psychology, 15</em>, 72-101.</p>
<p>Spearman, C. (1907). Demonstration of formulae for true measurement of correlation. <em>The American Journal of Psychology, 18</em>, 161-169.</p>
<p>Televantou, I., Marsh, H. W., Kyriakides, L., Nagengast, B., Fletcher, J., &amp; Malmberg, L. E. (2015). Phantom effects in school composition research: Consequences of failure to control biases due to measurement error in traditional multilevel models. <em>School Effectiveness and School Improvement, 26</em>, 75-101.</p>
<p>Van de Schoot, R., Kaplan, D., Denissen, J., Asendorpf, J. B., Neyer, F. J., &amp; van Aken, M. A. G. (2014). A gentle introduction to Bayesian analysis: Applications to developmental research. <em>Child Development, 85</em>, 842–860.</p>
<p>Van de Schoot, R., Lugtig, P., &amp; Hox, J. (2012). A checklist for testing measurement invariance. <em>European Journal of Developmental Psychology, 9</em>, 486–492.</p>
<p>Van der Maas, H. L. J., Dolan, C. V., Grasman, R. P. P. P., Wicherts, J. M., Huizenga, H. M., &amp; Raijmakers, M. E. J. (2006). A dynamical model of general intelligence: The positive manifold of intelligence by mutualism. <em>Psychological Review, 113</em>, 842–861.</p>
<p>Wright, S. (1918). On the nature of size factors. <em>Genetics, 3</em>, 367-374.</p>
<p>Wright, S. (1921). Correlation and causation. <em>Journal of agricultural research, 20, </em>557-585.</p>
<p>Wright, S. (1934). The method of path coefficients. <em>The Annals of Mathematical Statistics, 5</em>, 161-215.</p>
